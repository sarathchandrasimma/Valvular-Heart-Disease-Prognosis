{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm9J34o9WlgS",
        "outputId": "04ef0948-0de4-4d36-cea4-7367637162d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   AGE  GENDER  AORTIC VALVE  LEFT ATRIUM  EDD  ESD    EF  IVS (D)  PW (D)  \\\n",
            "0   52       1             1          3.5  4.5  3.0  60.0      1.2     1.2   \n",
            "1   21       1             0          3.0  4.3  2.6  66.0      1.0     1.0   \n",
            "2   55       1             1          3.4  4.5  2.9  65.0      1.2     1.2   \n",
            "3   42       1             1          3.7  4.8  3.6  35.0      1.2     1.2   \n",
            "4   38       0             0          3.4  4.3  2.7  64.0      1.0     1.0   \n",
            "\n",
            "   AORTA  I.A.S  RVSP  RWMA  TARGET  \n",
            "0    2.7      1    35     0       1  \n",
            "1    2.7      1    30     0       0  \n",
            "2    2.2      1    40     0       1  \n",
            "3    2.8      1    40     1       1  \n",
            "4    2.7      1    33     0       0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "file_path = 'DataSet.csv'\n",
        "data = pd.read_csv(file_path, encoding='UTF-8-SIG')\n",
        "\n",
        "# Display the head of the DataFrame\n",
        "data_head = data.head()\n",
        "\n",
        "# Show the head of the DataFrame\n",
        "print(data_head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fySFmO8nWrZK",
        "outputId": "042f3f68-5379-4e7b-ee34-1f1421f2d11c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Values:\n",
            " AGE             0\n",
            "GENDER          0\n",
            "AORTIC VALVE    0\n",
            "LEFT ATRIUM     0\n",
            "EDD             0\n",
            "ESD             0\n",
            "EF              0\n",
            "IVS (D)         0\n",
            "PW (D)          0\n",
            "AORTA           0\n",
            "I.A.S           0\n",
            "RVSP            0\n",
            "RWMA            0\n",
            "TARGET          0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Rows: 960\n",
            "\n",
            "Data Types:\n",
            " AGE               int64\n",
            "GENDER            int64\n",
            "AORTIC VALVE      int64\n",
            "LEFT ATRIUM     float64\n",
            "EDD             float64\n",
            "ESD             float64\n",
            "EF              float64\n",
            "IVS (D)         float64\n",
            "PW (D)          float64\n",
            "AORTA           float64\n",
            "I.A.S             int64\n",
            "RVSP              int64\n",
            "RWMA              int64\n",
            "TARGET            int64\n",
            "dtype: object\n",
            "\n",
            "Summary Statistics:\n",
            "                AGE       GENDER  AORTIC VALVE  LEFT ATRIUM          EDD  \\\n",
            "count  1280.000000  1280.000000   1280.000000  1280.000000  1280.000000   \n",
            "mean     51.878125     0.625000      0.453125     3.471906     4.497813   \n",
            "std      15.549990     0.484312      0.497992     0.578890     0.331360   \n",
            "min       7.000000     0.000000      0.000000     0.000000     3.000000   \n",
            "25%      42.000000     0.000000      0.000000     3.400000     4.400000   \n",
            "50%      52.500000     1.000000      0.000000     3.400000     4.400000   \n",
            "75%      63.000000     1.000000      1.000000     3.500000     4.500000   \n",
            "max      90.000000     1.000000      1.000000     7.100000     6.500000   \n",
            "\n",
            "               ESD           EF      IVS (D)       PW (D)        AORTA  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean      3.158750    60.344375     1.133656     1.134281     2.714375   \n",
            "std       3.105855     8.669245     0.101904     0.102002     0.121418   \n",
            "min       1.600000     0.000000     0.700000     0.700000     1.800000   \n",
            "25%       2.800000    60.000000     1.100000     1.100000     2.700000   \n",
            "50%       2.900000    64.000000     1.200000     1.200000     2.700000   \n",
            "75%       3.000000    65.000000     1.200000     1.200000     2.800000   \n",
            "max      58.000000    70.000000     1.900000     1.900000     2.800000   \n",
            "\n",
            "            I.A.S         RVSP         RWMA       TARGET  \n",
            "count  1280.00000  1280.000000  1280.000000  1280.000000  \n",
            "mean      0.99375    34.834375     0.234375     0.737500  \n",
            "std       0.07884     6.527076     0.423773     0.440165  \n",
            "min       0.00000     3.000000     0.000000     0.000000  \n",
            "25%       1.00000    30.000000     0.000000     0.000000  \n",
            "50%       1.00000    35.000000     0.000000     1.000000  \n",
            "75%       1.00000    35.000000     0.000000     1.000000  \n",
            "max       1.00000    80.000000     1.000000     1.000000  \n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicate_rows = data.duplicated().sum()\n",
        "\n",
        "# Check for any obvious issues with data types\n",
        "data_types = data.dtypes\n",
        "\n",
        "# Summary statistics to identify any outliers or anomalies\n",
        "summary_statistics = data.describe()\n",
        "\n",
        "# Display the findings\n",
        "print('Missing Values:\\n', missing_values)\n",
        "print('\\nDuplicate Rows:', duplicate_rows)\n",
        "print('\\nData Types:\\n', data_types)\n",
        "print('\\nSummary Statistics:\\n', summary_statistics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a-Y4LvzWyT8",
        "outputId": "e82533e2-bfa0-4622-e50a-276c2b429025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        AGE    GENDER  AORTIC VALVE  LEFT ATRIUM       EDD       ESD  \\\n",
            "0  0.007841  0.774597      1.098588     0.048549  0.006604 -0.051133   \n",
            "1 -1.986509  0.774597     -0.910259    -0.815510 -0.597204 -0.179972   \n",
            "2  0.200842  0.774597      1.098588    -0.124262  0.006604 -0.083343   \n",
            "3 -0.635498  0.774597      1.098588     0.394173  0.912317  0.142126   \n",
            "4 -0.892833 -1.290994     -0.910259    -0.124262 -0.597204 -0.147763   \n",
            "\n",
            "         EF   IVS (D)    PW (D)     AORTA     I.A.S      RVSP      RWMA  \\\n",
            "0 -0.039739  0.651296  0.644538 -0.118439  0.079305  0.025385 -0.553283   \n",
            "1  0.652633 -1.312102 -1.316967 -0.118439  0.079305 -0.740954 -0.553283   \n",
            "2  0.537238  0.651296  0.644538 -4.238047  0.079305  0.791724 -0.553283   \n",
            "3 -2.924624  0.651296  0.644538  0.705483  0.079305  0.791724  1.807392   \n",
            "4  0.421842 -1.312102 -1.316967 -0.118439  0.079305 -0.281151 -0.553283   \n",
            "\n",
            "     TARGET  \n",
            "0  0.596601  \n",
            "1 -1.676163  \n",
            "2  0.596601  \n",
            "3  0.596601  \n",
            "4 -1.676163  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Select columns to scale, typically numerical columns\n",
        "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Apply scaling to the numerical columns\n",
        "data_scaled = data.copy()\n",
        "data_scaled[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Display the head of the scaled DataFrame\n",
        "data_scaled_head = data_scaled.head()\n",
        "\n",
        "# Show the head of the scaled DataFrame\n",
        "print(data_scaled_head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yaqh7RsGW2fX",
        "outputId": "cb42fe6e-87c7-4080-a862-92b43f01a833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA DataFrame (head):\n",
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.933810 -0.766635  0.361479 -0.274011 -0.253074  0.137433  0.507175   \n",
            "1  3.354016  0.932505 -0.128299 -0.785179 -0.366485  0.330822  0.316016   \n",
            "2 -0.408380 -1.027156  2.215161  1.529083 -0.095618  1.492463  1.767276   \n",
            "3 -2.870323  1.899700  0.589156 -0.102978 -0.991356  0.214460  0.052823   \n",
            "4  2.746999  0.726967 -0.646917  0.558223  0.599754 -0.841184 -0.266591   \n",
            "\n",
            "         7         8         9         10  \n",
            "0 -0.974882 -0.015375 -0.039891 -0.554265  \n",
            "1 -0.107148 -0.067071  0.550617 -0.532475  \n",
            "2 -1.530093 -2.176816 -0.371606  0.678073  \n",
            "3  0.478801  0.256710  0.574496 -0.757207  \n",
            "4  0.478233 -0.384944  0.301600  0.181355  \n",
            "\n",
            "Feature Scores:\n",
            "         Feature         Score\n",
            "13        TARGET  1.027786e+18\n",
            "8         PW (D)  5.924585e+02\n",
            "7        IVS (D)  5.829282e+02\n",
            "2   AORTIC VALVE  5.345481e+02\n",
            "0            AGE  1.777585e+02\n",
            "12          RWMA  1.562772e+02\n",
            "11          RVSP  9.537737e+01\n",
            "6             EF  9.193003e+01\n",
            "4            EDD  7.407913e+01\n",
            "3    LEFT ATRIUM  1.757773e+01\n",
            "5            ESD  6.857640e+00\n",
            "10         I.A.S  2.867308e+00\n",
            "1         GENDER  1.721444e+00\n",
            "9          AORTA  1.621915e-01\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Apply PCA for feature extazraction\n",
        "pca = PCA(n_components=0.95) # Keep 95% of variance\n",
        "principal_components = pca.fit_transform(data_scaled[numerical_cols])\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "pca_df = pd.DataFrame(data=principal_components)\n",
        "\n",
        "# Apply SelectKBest for feature selection\n",
        "selector = SelectKBest(f_classif, k='all')\n",
        "selector.fit(data_scaled[numerical_cols], data_scaled['TARGET'])\n",
        "\n",
        "# Get the scores for each feature\n",
        "feature_scores = selector.scores_\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "feature_scores_df = pd.DataFrame({'Feature': numerical_cols, 'Score': feature_scores})\n",
        "\n",
        "# Sort the DataFrame by the scores in descending order\n",
        "feature_scores_df = feature_scores_df.sort_values(by='Score', ascending=False)\n",
        "\n",
        "# Display the PCA DataFrame head and the feature scores\n",
        "print('PCA DataFrame (head):')\n",
        "print(pca_df.head())\n",
        "print('\\nFeature Scores:')\n",
        "print(feature_scores_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t4U4l9_XOTZ",
        "outputId": "4f5886d1-537f-42c9-b881-b8eb1f89bbdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid Model Accuracy: 0.97265625\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Load your dataset\n",
        "data_scaled = pd.read_csv('DataSet.csv')\n",
        "\n",
        "# Define your features (X) and target variable (y)\n",
        "X = data_scaled.drop('TARGET', axis=1)\n",
        "y = (data_scaled['TARGET'] > 0).astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Fit the Random Forest classifier on the training data\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Instantiate the SVM classifier\n",
        "svm_clf = SVC(kernel='linear')  # You can choose a different kernel based on your needs\n",
        "\n",
        "# Fit the SVM classifier on the training data\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Now, you can use both trained models for predictions or evaluation on the test set\n",
        "\n",
        "\n",
        "# Assuming 'data_scaled.csv' is your dataset file\n",
        "data_scaled = pd.read_csv('DataSet.csv')\n",
        "\n",
        "# Define your features (X) and target variable (y)\n",
        "X = data_scaled.drop('TARGET', axis=1)\n",
        "y = (data_scaled['TARGET'] > 0).astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Fit the Random Forest classifier on the training data\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Now, you can use the trained model for predictions or evaluation on the test set\n",
        "\n",
        "# Convert the target variable back to categorical\n",
        "y = (data_scaled['TARGET'] > 0).astype(int)\n",
        "\n",
        "# Split the data into training and testing sets again\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Retrain the Random Forest classifier\n",
        "rf_clf.fit(X_train, y_train)\n",
        "# Retrain the SVM classifier\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with both classifiers\n",
        "rf_predictions = rf_clf.predict(X_test)\n",
        "svm_predictions = svm_clf.predict(X_test)\n",
        "\n",
        "# Combine predictions - here we will simply average them\n",
        "hybrid_predictions = (rf_predictions + svm_predictions) / 2\n",
        "\n",
        "# Evaluate the hybrid model\n",
        "hybrid_accuracy = accuracy_score(y_test, hybrid_predictions.round())\n",
        "\n",
        "# Print the accuracy of the hybrid model\n",
        "print('Hybrid Model Accuracy:', hybrid_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY_On7pmXWDS",
        "outputId": "b33206d2-3f9f-47b2-a171-2c1b459200d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid Model Accuracy: 0.97265625\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Convert the target variable back to categorical\n",
        "X = data_scaled.drop('TARGET', axis=1)\n",
        "y = (data_scaled['TARGET'] > 0).astype(int)\n",
        "\n",
        "# Split the data into training and testing sets again\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Retrain the Random Forest classifier\n",
        "rf_clf.fit(X_train, y_train)\n",
        "# Retrain the SVM classifier\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with both classifiers\n",
        "rf_predictions = rf_clf.predict(X_test)\n",
        "svm_predictions = svm_clf.predict(X_test)\n",
        "\n",
        "# Combine predictions - here we will simply average them\n",
        "hybrid_predictions = (rf_predictions + svm_predictions) / 2\n",
        "\n",
        "# Evaluate the hybrid model\n",
        "hybrid_accuracy = accuracy_score(y_test, hybrid_predictions.round())\n",
        "\n",
        "# Print the accuracy of the hybrid model\n",
        "print('Hybrid Model Accuracy:', hybrid_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PLX-WoQXYTy",
        "outputId": "40cf9688-4839-448c-8713-021ec5063d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated scores: [0.984375   0.984375   0.98046875 0.9765625  0.98828125]\n",
            "Mean accuracy: 0.9828125\n",
            "Standard deviation: 0.003983608994994363\n"
          ]
        }
      ],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "class HybridModel(BaseEstimator):\n",
        "    def __init__(self):\n",
        "        self.rf_clf = RandomForestClassifier(random_state=42)\n",
        "        self.svm_clf = SVC(probability=True, random_state=42)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.rf_clf.fit(X, y)\n",
        "        self.svm_clf.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        rf_predictions = self.rf_clf.predict_proba(X)[:, 1]\n",
        "        svm_predictions = self.svm_clf.decision_function(X)\n",
        "        hybrid_predictions = (rf_predictions + svm_predictions) / 2\n",
        "        return (hybrid_predictions > 0.5).astype(int)\n",
        "\n",
        "# Initialize the hybrid model\n",
        "hybrid_model = HybridModel()\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(hybrid_model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Calculate the mean and standard deviation of the cross-validation scores\n",
        "mean_score = scores.mean()\n",
        "std_dev_score = scores.std()\n",
        "\n",
        "# Display the results\n",
        "print('Cross-validated scores:', scores)\n",
        "print('Mean accuracy:', mean_score)\n",
        "print('Standard deviation:', std_dev_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LTDtB91XcYw",
        "outputId": "9f05d12f-cac4-452f-cc4a-3d92d7db7b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score     support\n",
            "0              0.946429  0.946429  0.946429   56.000000\n",
            "1              0.985000  0.985000  0.985000  200.000000\n",
            "accuracy       0.976562  0.976562  0.976562    0.976562\n",
            "macro avg      0.965714  0.965714  0.965714  256.000000\n",
            "weighted avg   0.976562  0.976562  0.976562  256.000000\n"
          ]
        }
      ],
      "source": [
        "# Fit the hybrid model on the entire dataset\n",
        "\n",
        "hybrid_model.fit(X, y)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = hybrid_model.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "from sklearn.metrics import classification_report\n",
        "performance_metrics = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Convert performance metrics to a DataFrame for better visualization\n",
        "import pandas as pd\n",
        "performance_df = pd.DataFrame(performance_metrics).transpose()\n",
        "\n",
        "# Print all the output performance metrics\n",
        "print(performance_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
